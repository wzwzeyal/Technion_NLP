name: Tweet4.2_azure_40 # Experiment name to save in the logger
seed: 42  # Random seed for reproducibility
num_epochs: 40   # Number of epochs to train the model
learning_rate: 0.0001
accumulation_steps: 1
do_train: true
do_eval_on_train: true  # Run evaluation on train set in the end of every epoch
do_eval: true  # Evaluate on dev set at the end of every epoch
do_test: false  # Evaluate on test set at the end of training

data_args:
  max_seq_length: 64
  batch_size: 64
  shuffle: True
  eval_batch_size: 4  # Batch size for evaluation
  minimum_vocab_freq_threshold: 1

model_args:
  output_size: 5  # Should correspond to the number of classes
  dropout: 0.2  # Dropout of the final classifier in the model
  weight_requires_grad: False
  cat_max_and_mean: False
  seq_model_name: LSTM
  embedding_model: glove-wiki-gigaword # https://github.com/RaRe-Technologies/gensim-data
  seq_args:
    hidden_size: 256  # Size of the hidden state of the LSTM
    bidirectional: True
    input_size: 300  # Size of the input to the LSTM
    num_layers: 3
    bias: true
    batch_first: true
    dropout: 0.2
