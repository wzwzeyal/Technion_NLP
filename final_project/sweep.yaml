# All configuration details could be found here https://docs.wandb.ai/guides/sweeps/
project: final_project_sweep
program: main.py
name: bayes
method: bayes
metric:
  goal: maximize
  name: eval/f1
parameters:
  num_train_epochs:
    values: [5, 10]
  learning_rate:
    values: [1e-5, 5e-5, 1e-4]
  is_perform_word_cleaning:
    values: [true, false]
  model_name_or_path:
    # https://github.com/aub-mind/arabert
    values: ["aubmindlab/bert-base-arabertv02",
             "CAMeL-Lab/bert-base-arabic-camelbert-mix-ner",
             "aubmindlab/bert-base-arabertv02-twitter",
             "aubmindlab/bert-base-arabertv2"
             "asafaya/bert-base-arabic"
             "hatmimoha/arabic-ner"
            ]
early_terminate:
  type: hyperband
  min_iter: 90
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - "--run_name"
  - "auto"
  - "--output_dir"
  - "auto"
  - "--overwrite_output_dir"
  - "true"
  - "--dataset_path"
  - "./data/iahlt-release-2022-06-09/ne/ar"
  - "--do_train"
  - "true"
  - "--tokenizers_parallelism"
  - "false"
  - "--force_create"
  - "false"
  - "--dataset_tag_field"
  - "name_tags"
  - "--seed"
  - "42"
  - "--fp16"
  - "true"
  - "--auto_find_batch_size"
  - "true"
  - "--gradient_accumulation_steps"
  - "2"
  - "--lr_scheduler_type"
  - "cosine"
  - "--max_train_samples"
  - "512"
  - "--max_eval_samples"
  - "128"
  - ${args}